{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tilakraj-B/cardiac-disease/blob/main/Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "3BIKvZCbVjIg"
      },
      "outputs": [],
      "source": [
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile\n",
        "from google.colab import drive\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, UpSampling2D, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from sklearn.cluster import KMeans\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRsbK4BQZlkp"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vaS5QdR-hKTq",
        "outputId": "94914cf9-1edb-447b-d12a-a4875259a4bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "0NLwWNEthU-u"
      },
      "outputs": [],
      "source": [
        "dataset_path = \"/content/drive/MyDrive/acdc_dataset.zip\"  # Update this path\n",
        "extract_folder = \"/content/acdc_data\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lH1qeuBnhyDM",
        "outputId": "d0c9bd9e-1fcb-45a3-dc7e-51fe71303887"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting dataset...\n",
            "Extraction complete.\n"
          ]
        }
      ],
      "source": [
        "# Step 3: Extract the dataset if not already extracted\n",
        "if not os.path.exists(extract_folder):\n",
        "    print(\"Extracting dataset...\")\n",
        "    with zipfile.ZipFile(dataset_path, \"r\") as zip_ref:\n",
        "        zip_ref.extractall(extract_folder)\n",
        "    print(\"Extraction complete.\")\n",
        "else:\n",
        "    print(\"Dataset already extracted.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0EAoR5_piNUe"
      },
      "outputs": [],
      "source": [
        "def load_nii_file(filepath):\n",
        "    img = nib.load(filepath)\n",
        "    data = img.get_fdata()\n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ae5MWnmJiQlb"
      },
      "outputs": [],
      "source": [
        "# Step 5: Load and visualize a sample image (Modify the path based on extracted files)\n",
        "base_dir = os.path.join(extract_folder,\"database\")\n",
        "training_folder = os.path.join(extract_folder,\"database\",\"training\")\n",
        "testing_folder = os.path.join(extract_folder,\"database\",\"testing\")\n",
        "train_patients = [f'patient{i:03d}' for i in range(1, 100)]\n",
        "test_patients = [f'patient{i:03d}' for i in range(1, 50)]\n",
        "\n",
        "# info_file_path = os.path.join(patient_folder, \"Info.cfg\")\n",
        "\n",
        "# if os.path.exists(info_file_path):\n",
        "#     with open(info_file_path, \"r\") as file:\n",
        "#         info_content = file.read()\n",
        "#     print(\"Contents of Info.cfg:\\n\")\n",
        "#     print(info_content)\n",
        "# else:\n",
        "#     print(\"Info.cfg not found. Check the path!\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LGIFbM82rcWG"
      },
      "outputs": [],
      "source": [
        "# Display all the images of a patient\n",
        "\n",
        "def display_nifti_slices(nifti_path):\n",
        "    nifti_img = nib.load(nifti_path)  # Load NIfTI file\n",
        "    image_data = nifti_img.get_fdata()  # Convert to NumPy array\n",
        "\n",
        "    print(f\"\\nDisplaying slices for {os.path.basename(nifti_path)}\")\n",
        "    print(f\"Image shape: {image_data.shape}\")  # Print shape\n",
        "\n",
        "    dim = image_data.ndim  # Get number of dimensions\n",
        "    if dim == 2:  # Case: 2D Image\n",
        "        plt.figure(figsize=(6, 6))\n",
        "        plt.imshow(image_data, cmap=\"gray\")\n",
        "        plt.title(f\"{os.path.basename(nifti_path)} - 2D Image\")\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()\n",
        "\n",
        "    elif dim == 3:  # Case: 3D Image (H, W, D)\n",
        "        num_slices = image_data.shape[2]\n",
        "        for i in range(num_slices):\n",
        "            plt.figure(figsize=(6, 6))\n",
        "            plt.imshow(image_data[:, :, i], cmap=\"gray\")\n",
        "            plt.title(f\"{os.path.basename(nifti_path)} - Slice {i+1}/{num_slices}\")\n",
        "            plt.axis(\"off\")\n",
        "            plt.show()\n",
        "\n",
        "    elif dim == 4:  # Case: 4D Image (H, W, D, T)\n",
        "        num_slices = image_data.shape[2]\n",
        "        num_timeframes = image_data.shape[3]\n",
        "        for t in range(num_timeframes):  # Loop over time\n",
        "            for i in range(num_slices):  # Loop over depth\n",
        "                plt.figure(figsize=(6, 6))\n",
        "                plt.imshow(image_data[:, :, i, t], cmap=\"gray\")\n",
        "                plt.title(f\"{os.path.basename(nifti_path)} - Time {t+1}/{num_timeframes} - Slice {i+1}/{num_slices}\")\n",
        "                plt.axis(\"off\")\n",
        "                plt.show()\n",
        "\n",
        "    else:\n",
        "        print(f\"Unsupported image dimension: {dim}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "0JnBpp3DBzVn"
      },
      "outputs": [],
      "source": [
        "# # displaying dimension and shape of the imagedatabase\n",
        "# for i in range(1,100):\n",
        "#   patient_folder = os.path.join(training_folder, f\"patient{i:03d}\")\n",
        "#   for filename in sorted(os.listdir(patient_folder)):\n",
        "#     if filename.endswith(\".nii\"):\n",
        "#       nifti_path = os.path.join(patient_folder, filename)\n",
        "#       # display_nifti_slices(nifti_path)\n",
        "#       nifti_img = nib.load(nifti_path)  # Load NIfTI file\n",
        "#       image_data = nifti_img.get_fdata()  # Convert to NumPy array\n",
        "#       dim = image_data.ndim\n",
        "#       # print(filename + \" : \" + str(dim) + \" dimensions\" + str(image_data.shape))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "bY5ugKFetrlC"
      },
      "outputs": [],
      "source": [
        "# Define a function to extract the ROI based on the ground truth mask\n",
        "def extract_roi(image_slice, mask_slice, margin=10):\n",
        "    \"\"\"\n",
        "    Given an image and its binary mask, this function computes the bounding box\n",
        "    around the mask and crops both the image and mask with an optional margin.\n",
        "    \"\"\"\n",
        "    # Find coordinates of the mask pixels\n",
        "    coords = np.where(mask_slice > 0)\n",
        "    if coords[0].size == 0 or coords[1].size == 0:\n",
        "        # If no ROI found, return the original slices\n",
        "        return image_slice, mask_slice\n",
        "\n",
        "    y_min, y_max = coords[0].min(), coords[0].max()\n",
        "    x_min, x_max = coords[1].min(), coords[1].max()\n",
        "\n",
        "    # Add margin (ensuring we stay within image bounds)\n",
        "    y_min = max(y_min - margin, 0)\n",
        "    y_max = min(y_max + margin, image_slice.shape[0])\n",
        "    x_min = max(x_min - margin, 0)\n",
        "    x_max = min(x_max + margin, image_slice.shape[1])\n",
        "\n",
        "    return image_slice[y_min:y_max, x_min:x_max], mask_slice[y_min:y_max, x_min:x_max]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ttP1aY1bkkzr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ZgCIXAAB3EM4"
      },
      "outputs": [],
      "source": [
        "def load_patient_data(patient_folder):\n",
        "    # Get all .nii files in the folder\n",
        "    files = [f for f in os.listdir(patient_folder) if f.endswith('.nii') and not f.endswith('4d.nii')]\n",
        "\n",
        "    # Separate image and ground truth files\n",
        "    image_files = [f for f in files if not f.endswith('_gt.nii')]\n",
        "    gt_files = [f for f in files if f.endswith('_gt.nii')]\n",
        "\n",
        "    images = []\n",
        "    masks = []\n",
        "\n",
        "    for img_file, gt_file in zip(sorted(image_files), sorted(gt_files)):\n",
        "        img_data = load_nii_file(os.path.join(patient_folder, img_file))\n",
        "        gt_data = load_nii_file(os.path.join(patient_folder, gt_file))\n",
        "\n",
        "        #iterating through each slice in the model\n",
        "        for slice_idx in range(img_data.shape[2]):\n",
        "            img_slice = img_data[..., slice_idx]\n",
        "            gt_slice = gt_data[..., slice_idx]\n",
        "\n",
        "            # Normalize and resize if needed\n",
        "            img_slice = (img_slice - img_slice.min()) / (img_slice.max() - img_slice.min())\n",
        "            gt_slice = (gt_slice > 0).astype(np.float32)  # Binarize if needed\n",
        "\n",
        "            # ROI Extraction Step\n",
        "            img_slice, gt_slice = extract_roi(img_slice, gt_slice, margin=10)\n",
        "\n",
        "            # Resize to make dimensions divisible by 16 for U-Net (optional)\n",
        "            img_slice = tf.image.resize(img_slice[..., np.newaxis], [224, 256])\n",
        "            gt_slice = tf.image.resize(gt_slice[..., np.newaxis], [224, 256])\n",
        "\n",
        "            images.append(img_slice.numpy())\n",
        "            masks.append(gt_slice.numpy())\n",
        "\n",
        "    return np.array(images), np.array(masks)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XA9Sdc_13eAt"
      },
      "outputs": [],
      "source": [
        "def load_dataset(root_folder, patient_range):\n",
        "    all_images = []\n",
        "    all_masks = []\n",
        "\n",
        "    for patient_id in patient_range:\n",
        "        patient_folder = os.path.join(root_folder, f\"patient{patient_id:03d}\")\n",
        "        if os.path.exists(patient_folder):\n",
        "            images, masks = load_patient_data(patient_folder)\n",
        "            all_images.extend(images)\n",
        "            all_masks.extend(masks)\n",
        "\n",
        "    return np.array(all_images), np.array(all_masks)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "F9vi-tQ_rWjS"
      },
      "outputs": [],
      "source": [
        "def unet_model(input_size=(224, 256, 1)):\n",
        "    inputs = Input(input_size)\n",
        "\n",
        "    # Downsample path with fewer filters\n",
        "    conv1 = Conv2D(32, 3, activation='relu', padding='same')(inputs)\n",
        "    conv1 = Conv2D(32, 3, activation='relu', padding='same')(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
        "\n",
        "    conv2 = Conv2D(64, 3, activation='relu', padding='same')(pool1)\n",
        "    conv2 = Conv2D(64, 3, activation='relu', padding='same')(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
        "\n",
        "    conv3 = Conv2D(128, 3, activation='relu', padding='same')(pool2)\n",
        "    conv3 = Conv2D(128, 3, activation='relu', padding='same')(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
        "\n",
        "    # Bottleneck\n",
        "    conv4 = Conv2D(256, 3, activation='relu', padding='same')(pool3)\n",
        "    conv4 = Conv2D(256, 3, activation='relu', padding='same')(conv4)\n",
        "\n",
        "    # Upsample path\n",
        "    up1 = Conv2D(128, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv4))\n",
        "    merge1 = concatenate([conv3, up1], axis=3)\n",
        "    conv5 = Conv2D(128, 3, activation='relu', padding='same')(merge1)\n",
        "    conv5 = Conv2D(128, 3, activation='relu', padding='same')(conv5)\n",
        "\n",
        "    up2 = Conv2D(64, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv5))\n",
        "    merge2 = concatenate([conv2, up2], axis=3)\n",
        "    conv6 = Conv2D(64, 3, activation='relu', padding='same')(merge2)\n",
        "    conv6 = Conv2D(64, 3, activation='relu', padding='same')(conv6)\n",
        "\n",
        "    up3 = Conv2D(32, 2, activation='relu', padding='same')(UpSampling2D(size=(2, 2))(conv6))\n",
        "    merge3 = concatenate([conv1, up3], axis=3)\n",
        "    conv7 = Conv2D(32, 3, activation='relu', padding='same')(merge3)\n",
        "    conv7 = Conv2D(32, 3, activation='relu', padding='same')(conv7)\n",
        "\n",
        "    outputs = Conv2D(1, 1, activation='sigmoid')(conv7)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "6cqUVbyhcs4S"
      },
      "outputs": [],
      "source": [
        "def train_model():\n",
        "    # Load training data\n",
        "    train_images, train_masks = load_dataset(training_folder, range(1, 101))\n",
        "\n",
        "    # Split into training and validation\n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        train_images, train_masks, test_size=0.2, random_state=42\n",
        "    )\n",
        "\n",
        "    # Create model\n",
        "    model = unet_model()\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.IoU(num_classes=2, target_class_ids=[1])])\n",
        "\n",
        "    # Callbacks\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.ModelCheckpoint('best_model.h5', save_best_only=True),\n",
        "        tf.keras.callbacks.EarlyStopping(patience=10, monitor='val_loss')\n",
        "    ]\n",
        "\n",
        "    # Train\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        batch_size=16,\n",
        "        epochs=100,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "\n",
        "    return model, history"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_kmeans_with_filters(segmented_image, k=3):\n",
        "    \"\"\"\n",
        "    Apply smoothing and sharpening filters to the segmented_image,\n",
        "    then apply K-means clustering (k=3) to segment it into regions.\n",
        "\n",
        "    Parameters:\n",
        "      segmented_image : 2D numpy array (grayscale)\n",
        "      k : number of clusters for K-means (default 3)\n",
        "\n",
        "    Returns:\n",
        "      clustered : the final K-means label image\n",
        "      smoothed_image : image after Gaussian smoothing\n",
        "      sharpened_image : image after sharpening filter\n",
        "    \"\"\"\n",
        "    # Apply Gaussian smoothing filter\n",
        "    smoothed_image = cv2.GaussianBlur(segmented_image, (5, 5), 0)\n",
        "\n",
        "    # Define a sharpening kernel and apply it\n",
        "    kernel_sharpening = np.array([[-1, -1, -1],\n",
        "                                  [-1,  9, -1],\n",
        "                                  [-1, -1, -1]])\n",
        "    sharpened_image = cv2.filter2D(smoothed_image, -1, kernel_sharpening)\n",
        "\n",
        "    # Flatten the sharpened image for clustering\n",
        "    flat_image = sharpened_image.reshape(-1, 1)\n",
        "\n",
        "    # Apply K-means clustering\n",
        "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
        "    kmeans.fit(flat_image)\n",
        "\n",
        "    # Reshape the cluster labels back to the original image shape\n",
        "    clustered = kmeans.labels_.reshape(segmented_image.shape)\n",
        "    return clustered, smoothed_image, sharpened_image\n"
      ],
      "metadata": {
        "id": "Ke8FQA6nAaNM"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "fqySk5hFBLKP"
      },
      "outputs": [],
      "source": [
        "def evaluate_model(model):\n",
        "    # Load test data\n",
        "    test_images, test_masks = load_dataset(testing_folder, range(101, 151))  # Assuming test data range is 101-150\n",
        "\n",
        "    # Evaluate\n",
        "    results = model.evaluate(test_images, test_masks)\n",
        "    print(f\"Test Loss: {results[0]}, Test Accuracy: {results[1]}, Test IoU: {results[2]}\")\n",
        "\n",
        "    # Predict\n",
        "    predicted_mask = model.predict(test_images[:10])\n",
        "\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(20, 10))\n",
        "    for i in range(10):\n",
        "        original_image = test_images[i].squeeze()\n",
        "        true_mask = test_masks[i].squeeze()\n",
        "        pred_mask = (predicted_mask[i].squeeze() > 0.7).astype(np.uint8)  # Binary mask\n",
        "\n",
        "        # Extract predicted region\n",
        "        segmented_image = original_image * pred_mask  # Element-wise multiplication\n",
        "\n",
        "        # Apply K-means clustering to the segmented image to get 3 regions\n",
        "        kmeans_clusters, smoothed_image, sharpened_image = apply_kmeans_with_filters(segmented_image, 3)\n",
        "\n",
        "        plt.subplot(7, 10, i + 1)\n",
        "        plt.imshow(original_image, cmap='gray')\n",
        "        plt.title('Input')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(7, 10, i + 11)\n",
        "        plt.imshow(true_mask, cmap='gray')\n",
        "        plt.title('Ground Truth')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(7, 10, i + 21)\n",
        "        plt.imshow(pred_mask, cmap='gray')\n",
        "        plt.title('Prediction Mask')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(7, 10, i + 31)\n",
        "        plt.imshow(segmented_image, cmap='gray')\n",
        "        plt.title('Segmented Region')\n",
        "        plt.axis('off')\n",
        "\n",
        "        # Plot K-means Clustering Result (3 regions)\n",
        "        plt.subplot(7, 10, i + 41)\n",
        "        plt.imshow(kmeans_clusters, cmap='jet')\n",
        "        plt.title('K-means Clusters')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(7, 10, i + 51)\n",
        "        plt.imshow(smoothed_image, cmap='jet')\n",
        "        plt.title('K-means Clusters')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(7, 10, i + 61)\n",
        "        plt.imshow(sharpened_image, cmap='jet')\n",
        "        plt.title('K-means Clusters')\n",
        "        plt.axis('off')\n",
        "\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "dzXT0DU5NMt3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koQHr49Db6il",
        "outputId": "dea68eec-3eb8-4ea3-9b4d-5a7ac9257174"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 313ms/step - accuracy: 0.6524 - io_u: 0.0000e+00 - loss: 0.6421"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 483ms/step - accuracy: 0.6528 - io_u: 0.0000e+00 - loss: 0.6416 - val_accuracy: 0.7367 - val_io_u: 0.0000e+00 - val_loss: 0.4534\n",
            "Epoch 2/100\n",
            "\u001b[1m95/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 225ms/step - accuracy: 0.8034 - io_u: 0.0000e+00 - loss: 0.3925"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 253ms/step - accuracy: 0.8038 - io_u: 0.0000e+00 - loss: 0.3918 - val_accuracy: 0.8617 - val_io_u: 0.0000e+00 - val_loss: 0.2798\n",
            "Epoch 3/100\n",
            "\u001b[1m95/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 230ms/step - accuracy: 0.8630 - io_u: 0.0000e+00 - loss: 0.2711"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 257ms/step - accuracy: 0.8631 - io_u: 0.0000e+00 - loss: 0.2710 - val_accuracy: 0.8755 - val_io_u: 0.0000e+00 - val_loss: 0.2445\n",
            "Epoch 4/100\n",
            "\u001b[1m95/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 238ms/step - accuracy: 0.8782 - io_u: 0.0000e+00 - loss: 0.2400"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 264ms/step - accuracy: 0.8783 - io_u: 0.0000e+00 - loss: 0.2397 - val_accuracy: 0.8966 - val_io_u: 0.0000e+00 - val_loss: 0.2005\n",
            "Epoch 5/100\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 260ms/step - accuracy: 0.8911 - io_u: 0.0000e+00 - loss: 0.2116 - val_accuracy: 0.8893 - val_io_u: 0.0000e+00 - val_loss: 0.2154\n",
            "Epoch 6/100\n",
            "\u001b[1m95/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 236ms/step - accuracy: 0.8946 - io_u: 0.0000e+00 - loss: 0.2031"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 254ms/step - accuracy: 0.8946 - io_u: 0.0000e+00 - loss: 0.2030 - val_accuracy: 0.9044 - val_io_u: 0.0000e+00 - val_loss: 0.1837\n",
            "Epoch 7/100\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 252ms/step - accuracy: 0.8844 - io_u: 0.0000e+00 - loss: 0.2280 - val_accuracy: 0.8961 - val_io_u: 0.0000e+00 - val_loss: 0.2019\n",
            "Epoch 8/100\n",
            "\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 251ms/step - accuracy: 0.8952 - io_u: 0.0000e+00 - loss: 0.2032 - val_accuracy: 0.8695 - val_io_u: 0.0000e+00 - val_loss: 0.2495\n",
            "Epoch 9/100\n",
            "\u001b[1m95/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 234ms/step - accuracy: 0.9016 - io_u: 0.0000e+00 - loss: 0.1869"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 261ms/step - accuracy: 0.9016 - io_u: 0.0000e+00 - loss: 0.1868 - val_accuracy: 0.9063 - val_io_u: 0.0000e+00 - val_loss: 0.1815\n",
            "Epoch 10/100\n",
            "\u001b[1m95/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 242ms/step - accuracy: 0.9101 - io_u: 0.0000e+00 - loss: 0.1670"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 269ms/step - accuracy: 0.9102 - io_u: 0.0000e+00 - loss: 0.1669 - val_accuracy: 0.9159 - val_io_u: 0.0000e+00 - val_loss: 0.1507\n",
            "Epoch 11/100\n",
            "\u001b[1m95/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 245ms/step - accuracy: 0.9163 - io_u: 0.0000e+00 - loss: 0.1482"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m96/96\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 262ms/step - accuracy: 0.9163 - io_u: 0.0000e+00 - loss: 0.1482 - val_accuracy: 0.9179 - val_io_u: 0.0000e+00 - val_loss: 0.1449\n",
            "Epoch 12/100\n",
            "\u001b[1m45/96\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m11s\u001b[0m 235ms/step - accuracy: 0.9224 - io_u: 0.0000e+00 - loss: 0.1340"
          ]
        }
      ],
      "source": [
        "    if not os.path.exists('unet_mri_segmentation.keras'):\n",
        "      model, history = train_model()\n",
        "      model.save('unet_mri_segmentation.keras')\n",
        "    else: model = tf.keras.models.load_model('unet_mri_segmentation.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W6fO613rdMnQ"
      },
      "outputs": [],
      "source": [
        "    # Evaluate on test set\n",
        "    evaluate_model(model)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyMUnCSOlbmUr4rPdbVSI8uQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}